import cv2
import numpy as np
import dlib
import os
import pickle


harrFeatureCascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')
predictor = dlib.shape_predictor("shape_predictor_68_face_landmarks.dat")
face_descriptor = dlib.face_recognition_model_v1("dlib_face_recognition_resnet_model_v1.dat")

def prepare_image(image, size):
    resized = cv2.resize(image, size)
    if len(resized.shape) == 2: 
        resized = cv2.cvtColor(resized, cv2.COLOR_GRAY2BGR)
    return resized

def add_label(image, label):
    font = cv2.FONT_HERSHEY_SIMPLEX
    font_scale = 0.8  
    color = (0, 255, 0) if label == 'Matched' else (0, 0, 255)  # Green for match, Red for not match
    thickness = 2
    text_size = cv2.getTextSize(label, font, font_scale, thickness)[0]
    text_x = (image.shape[1] - text_size[0]) // 2  
    text_y = 20  

    cv2.putText(image, label, (text_x, text_y), font, font_scale, color, thickness, lineType=cv2.LINE_AA)
    return image

def euclidean_distance(x, y):
    return np.sqrt(np.sum((x - y) ** 2))

def manhattan_distance(x, y):
    return np.sum(np.abs(x - y))

def cosine_similarity(x, y):
    dot_product = np.dot(x, y)
    norm_x = np.sqrt(np.sum(x ** 2))
    norm_y = np.sqrt(np.sum(y ** 2))
    return dot_product / (norm_x * norm_y)

def chi_square_distance(x, y):
    x = np.abs(x)
    y = np.abs(y)
    numerator = (x - y) ** 2
    denominator = x + y
    valid_indices = denominator != 0
    distance = np.sum(numerator[valid_indices] / denominator[valid_indices])
    return distance


def Get_Face_Feature(image_gray, face_rect):
    landmarks_points = []
    landmarks_features = []
    
    dlib_rect = dlib.rectangle(face_rect[0], face_rect[1], face_rect[0] + face_rect[2],face_rect[1] + face_rect[3])
    
    landmarks = predictor(image_gray, dlib_rect) # to get 68 point represent the face
    
    for i in range(0, 68):
        x = landmarks.part(i).x
        y = landmarks.part(i).y
        landmarks_points.append((x, y))
        
        patch = image_gray[y-5:y+5, x-5:x+5] #cell in this point 10 * 10 with data in it
        if patch.size > 0: # check if patch vaild and have correct data 
            patch_features = cv2.resize(patch, (5, 5)).flatten() # convert patch to 5*5 and 1D array 
            landmarks_features.append(patch_features) # push 1D array
    
    return landmarks_points, np.concatenate(landmarks_features) , landmarks # -2- concatenate all sub 1D array to only 1D array


def Detect_Face(image_path , type = 0):
    if type == 0 : img = cv2.imread(image_path)
    else : img = image_path
    image_gray = cv2.cvtColor(img , cv2.COLOR_BGR2GRAY)
    result = harrFeatureCascade.detectMultiScale(image_gray , 1.1, 4)
    all_face_features = []
    for face in result:
        landmarks_points, local_features , landmarks = Get_Face_Feature(image_gray, face) # point and data of cell that contain this point
        cv2.rectangle(img , (face[0], face[1]), (face[0] + face[2] , face[1] + face[3]), (10,255,20), 2)

        face_desc = face_descriptor.compute_face_descriptor(img, landmarks) # unique descrip for face with applying point of landmarks on it
        combined_features = np.concatenate([local_features,np.array(face_desc)]) #concatenate in 1D with face_desc and local_features
        combined_features = combined_features / np.linalg.norm(combined_features) #Normalized 
        all_face_features.append({'combined_features': combined_features})
        
        for (x, y) in landmarks_points:cv2.circle(img, (x, y), 2, (255, 20, 10), -1)
    return img, all_face_features
    

def Face_Similarity(features1, features2):
    vec1 = features1['combined_features']
    vec2 = features2['combined_features']
    
    cosine_sim = cosine_similarity(vec1, vec2)
    euclidean_sim = 1 / (1 + euclidean_distance(vec1, vec2))
    manhattan_sim = 1 / (1 + manhattan_distance(vec1, vec2))
    chi_square_sim = 1 / (1 + chi_square_distance(vec1, vec2))
    
    return {'cosine': cosine_sim,'euclidean': euclidean_sim,'manhattan': manhattan_sim,'chi_square': chi_square_sim}



def Is_The_Same_Face(features1, features2, thresholds=None):
    if thresholds is None:
        thresholds = {'cosine': 0.6,'euclidean': 0.8,'manhattan': 0.4,'chi_square': 0.3}
        similarities = Face_Similarity(features1, features2)
    
    results = {}
    for method, score in similarities.items():
        threshold = thresholds[method]
        is_match = score >= threshold
        results[method] = {'score': score,'is_match': is_match,'threshold': threshold}    
    return results  
    
images = []
features = []

gallary_folder = "gallary"
j = 0
for file in os.listdir(gallary_folder):
    image_path = os.path.join(gallary_folder , file)
    images.append([])
    features.append([])
    images[j] , features[j] = Detect_Face(image_path) 
    j = j + 1

cap = cv2.VideoCapture(0)

# Check if the webcam is opened correctly
if not cap.isOpened():
    print("Error: Could not access the webcam.")
    exit()

# Capture a frame from the webcam
ret, Test = cap.read()

# Check if the frame was successfully captured
if not ret:
    print("Error: Could not capture frame.")
    exit()

# Release the webcam after capturing
cap.release()


# Perform face detection and feature extraction on the captured frame
Test, Testfeatures = Detect_Face(Test , 1)

# Results initialization
resultsN = [0.0, 0.0, 0.0]
resultsI = [images[0], images[1], images[2]]
resultsM = [0, 0, 0]

# Compare the captured image with the gallery images
for i in range(len(images)):  
    face_result = Is_The_Same_Face(Testfeatures[0], features[i][0])  
    if face_result['euclidean']['score'] > resultsN[0]:
        resultsN[0] = face_result['euclidean']['score']
        resultsI[0] = images[i]
        resultsM[0] = face_result['euclidean']['is_match']
    elif face_result['euclidean']['score'] > resultsN[1]:
        resultsN[1] = face_result['euclidean']['score']
        resultsI[1] = images[i]
        resultsM[1] = face_result['euclidean']['is_match']
    elif face_result['euclidean']['score'] > resultsN[2]:
        resultsN[2] = face_result['euclidean']['score']
        resultsI[2] = images[i]
        resultsM[2] = face_result['euclidean']['is_match']

# Prepare the results images
common_size = (300, 300)
j = 0
for img in resultsI :
    resultsI[j] = prepare_image(img, common_size)
    j = j + 1
     
labeled_results = []
for i, img in enumerate(resultsI):
    label = 'Matched' if resultsM[i] == 1 else 'Not Matched'
    labeled_img = add_label(img, label)
    labeled_results.append(labeled_img)

# Resize the images for display consistency
Test_prepared = prepare_image(Test, common_size)
labeled_results_prepared = [img for img in labeled_results]

# Concatenate the images horizontally
results_combined = cv2.hconcat([Test_prepared] + labeled_results_prepared)

# Display the final result
cv2.imshow('Results', results_combined)
cv2.waitKey(0)
cv2.destroyAllWindows()

